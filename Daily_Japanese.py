import google.generativeai as genai
import requests
import os
import json
import random
import re
from datetime import datetime, timedelta
import time

# ================= ç’°å¢ƒè®Šæ•¸ =================
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
TG_BOT_TOKEN = os.getenv("TG_BOT_TOKEN")
TG_CHAT_ID = os.getenv("TG_CHAT_ID")

# æª”æ¡ˆè¨­å®š
VOCAB_FILE = "vocab.json"
USER_DATA_FILE = "user_data.json"
MODEL_NAME = 'models/gemini-2.5-flash' # ç©©å®šä¸”é¡åº¦è¼ƒé«˜

# å®‰å…¨è¨­å®š
SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
]

# ================= æª”æ¡ˆå­˜å–å·¥å…· =================

def load_json(filename, default_content):
    if os.path.exists(filename):
        try:
            with open(filename, "r", encoding="utf-8") as f:
                data = json.load(f)
                # ç°¡å–®åˆä½µé è¨­å€¼
                if isinstance(data, dict) and isinstance(default_content, dict):
                    for k, v in default_content.items():
                        if k not in data: data[k] = v
                return data
        except: return default_content
    return default_content

def save_json(filename, data):
    # Log æˆªæ–· (ä¿ç•™æœ€è¿‘ 30 ç­†ç¿»è­¯ç´€éŒ„)
    if filename == USER_DATA_FILE and "translation_log" in data:
        if len(data["translation_log"]) > 30:
            data["translation_log"] = data["translation_log"][-30:]
            
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def send_telegram(message):
    if not TG_BOT_TOKEN: print(f"[æ¨¡æ“¬ç™¼é€] {message[:50]}..."); return
    clean_msg = message.replace("**", "").replace("##", "").replace("__", "")
    try:
        requests.post(f"https://api.telegram.org/bot{TG_BOT_TOKEN}/sendMessage", json={
            "chat_id": TG_CHAT_ID, "text": clean_msg
        })
    except Exception as e: print(f"TG ç™¼é€å¤±æ•—: {e}")

def normalize_text(text):
    if not text: return ""
    return text.strip().replace("ã€€", " ").lower()

# ================= AI æ ¸å¿ƒï¼šæ‰¹æ”¹èˆ‡åˆ†æ =================

def ai_correction(user_text, translation_history):
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel(MODEL_NAME)
    
    print(f"ğŸ¤– AI æ­£åœ¨æ‰¹æ”¹: {user_text[:20]}...")
    
    # çµ„åˆæ­·å²ç´€éŒ„å­—ä¸²
    history_str = "\n".join(translation_history[-10:]) if translation_history else "(å°šç„¡æ­·å²ç´€éŒ„)"
    
    prompt = f"""
    ä½¿ç”¨è€…æ­£åœ¨ç·´ç¿’æ—¥æ–‡ï¼ˆåŒ…å«ä½œæ¥­å›ç­”èˆ‡éš¨å ‚ç·´ç¿’ï¼‰ï¼Œé€™æ˜¯å¥¹å‰›å‰›å‚³ä¾†çš„å…§å®¹ï¼š
    ã€Œ{user_text}ã€
    
    ã€ä½¿ç”¨è€…çš„æ­·å²ç¿»è­¯ç´€éŒ„ (ç”±èˆŠåˆ°æ–°)ã€‘
    {history_str}
    
    è«‹æ‰®æ¼”ä¸€ä½ã€è§€å¯Ÿå…¥å¾®ä¸”åš´æ ¼çš„æ—¥æ–‡æ•™æˆã€‘ï¼Œå®Œæˆä»¥ä¸‹ä»»å‹™ï¼š
    
    1. **ğŸ“ˆ é€²åº¦è©•ä¼° (é‡é»)**ï¼š
       - æ¯”è¼ƒä»Šå¤©çš„å¥å­èˆ‡æ­·å²ç´€éŒ„ã€‚
       - **åˆ¤æ–·é€²æ­¥**ï¼šæ–‡æ³•æ˜¯å¦è®Šç²¾æº–ï¼Ÿè©å½™é‡æ˜¯å¦å¢åŠ ï¼Ÿ
       - **çµ¦äºˆå›é¥‹**ï¼šè«‹åœ¨é–‹é ­æ˜ç¢ºçµ¦äºˆé¼“å‹µ (å¦‚ï¼šã€Œçœ‹åˆ°å¦³é–‹å§‹å˜—è©¦é•·é›£å¥äº†ï¼Œå¾ˆæ£’ï¼ã€) æˆ–æ˜¯è­¦æƒ• (å¦‚ï¼šã€Œæ€éº¼åŠ©è©é‚„æ˜¯ç”¨éŒ¯ï¼Ÿã€)ã€‚
       
    2. **ğŸ¯ æ‰¹æ”¹èˆ‡ä¿®æ­£**ï¼š
       - å¦‚æœæ˜¯å¤šå¥å›ç­”ï¼Œè«‹é€ä¸€ç°¡å–®æ‰¹æ”¹ã€‚
       - ä¿®æ­£éŒ¯èª¤ (âœ… æˆ– âŒ)ã€‚
    
    3. **âœ¨ ä¸‰ç¨®å¤šæ¨£åŒ–è¡¨é” (é‡å°å…¶ä¸­ä¸€å¥ä¸»è¦æ„æ€)**ï¼š
       è«‹æä¾›ä»¥ä¸‹ä¸‰ç¨®èªªæ³•ï¼š
       - ğŸ‘” **æ­£å¼ (Formal)**
       - ğŸ» **å£èª (Casual)**
       - ğŸ”„ **æ›å¥è©±èªª (Paraphrase)**
    
    ã€è¼¸å‡ºæ ¼å¼ã€‘
    ç¹é«”ä¸­æ–‡ï¼ŒEmoji æ’ç‰ˆï¼Œ**ä¸è¦** Markdown ç²—é«”ã€‚
    """
    
    try:
        response = model.generate_content(prompt, safety_settings=SAFETY_SETTINGS)
        return response.text if response.text else "âš ï¸ AI æ‰¹æ”¹å¤±æ•—"
    except Exception as e:
        return f"âš ï¸ AI æ‰¹æ”¹éŒ¯èª¤: {e}"

# ================= é‚è¼¯æ ¸å¿ƒï¼šè™•ç†è¨Šæ¯ =================

def process_data():
    print("ğŸ“¥ é–‹å§‹è™•ç†è³‡æ–™...")
    
    vocab_data = load_json(VOCAB_FILE, {"words": []})
    user_data = load_json(USER_DATA_FILE, {
        "stats": {
            "last_active": "2000-01-01", 
            "streak_days": 0,
            "last_quiz_date": "2000-01-01",
            "last_quiz_questions_count": 0, # æ˜¨å¤©å‡ºäº†å¹¾é¡Œ
            "yesterday_answers_count": 0    # æ˜¨å¤©å›äº†å¹¾é¡Œ (å«éš¨å ‚ç·´ç¿’)
        },
        "translation_log": [] 
    })
    
    url = f"https://api.telegram.org/bot{TG_BOT_TOKEN}/getUpdates"
    
    try:
        response = requests.get(url).json()
        if "result" not in response: return vocab_data, user_data
        
        is_vocab_updated = False
        is_user_updated = False
        updates_log = []
        correction_msgs = []
        
        today_str = str(datetime.now().date())
        today_answers_accumulated = 0

        for item in response["result"]:
            if str(item["message"]["chat"]["id"]) != str(TG_CHAT_ID): continue
            
            msg_time = datetime.fromtimestamp(item["message"]["date"])
            if datetime.now() - msg_time > timedelta(hours=24): continue
            
            text = item["message"].get("text", "").strip()
            if not text: continue

            # === Case A: JSON æ–‡å­—åŒ¯å…¥ (ä»¥ [ é–‹é ­) ===
            if text.startswith("["):
                try:
                    imported = json.loads(text)
                    if isinstance(imported, list):
                        added = 0
                        for word in imported:
                            if "kanji" not in word: continue
                            kanji = word.get("kanji")
                            if not any(normalize_text(w["kanji"]) == normalize_text(kanji) for w in vocab_data["words"]):
                                vocab_data["words"].append({
                                    "kanji": kanji, "kana": word.get("kana", ""),
                                    "meaning": word.get("meaning", ""),
                                    "count": 1, "added_date": today_str
                                })
                                added += 1
                                is_vocab_updated = True
                        updates_log.append(f"ğŸ“‚ åŒ¯å…¥ {added} å€‹æ–°å–®å­—")
                except: pass
                continue

            # === Case B: å­˜å–®å­—æŒ‡ä»¤ (æ ¼å¼: æ¼¢å­— å‡å æ„æ€) ===
            match = re.search(r"^(\S+)[ \u3000]+(\S+)[ \u3000]+(.+)$", text)
            # å¿…é ˆç¢ºä¿å®ƒä¸åƒæ˜¯ä¸€å¥æ—¥æ–‡ (ç°¡å–®åˆ¤æ–·ï¼šæ˜¯å¦æœ‰åŠ©è©æˆ–æ¨™é»ï¼Œé€™è£¡ç”¨ Regex å¼·åˆ¶ä¸‰å€‹å€å¡Š)
            # å¦‚æœç¬¦åˆå­˜å–®å­—æ ¼å¼
            if match and len(text.split()) == 3:
                kanji, kana, meaning = match.groups()
                found = False
                for word in vocab_data["words"]:
                    if normalize_text(word["kanji"]) == normalize_text(kanji):
                        word["count"] += 1 
                        updates_log.append(f"ğŸ”„ å¼·åŒ–è¨˜æ†¶ï¼š{kanji}")
                        found = True
                        is_vocab_updated = True
                        break
                if not found:
                    vocab_data["words"].append({
                        "kanji": kanji, "kana": kana, "meaning": meaning, 
                        "count": 1, "added_date": today_str
                    })
                    updates_log.append(f"âœ… æ”¶éŒ„ï¼š{kanji}")
                    is_vocab_updated = True
                continue

            # === Case C: ç¿»è­¯/äº¤ä½œæ¥­/éš¨å ‚ç·´ç¿’ (æ‰€æœ‰å…¶ä»–æ–‡å­—) ===
            elif not text.startswith("/"):
                # 1. è¨ˆç®—ç­”é¡Œé‡ (ç°¡å–®ç®—æ³•ï¼šä»¥æ›è¡Œç¬¦è™Ÿåˆ¤æ–·å›ç­”äº†å¹¾é¡Œï¼Œè‡³å°‘ç®— 1 é¡Œ)
                lines_count = len([l for l in text.split('\n') if len(l.strip()) > 1])
                lines_count = max(1, lines_count)
                today_answers_accumulated += lines_count
                
                # 2. AI æ‰¹æ”¹ & åˆ†æ
                result = ai_correction(text, user_data["translation_log"])
                correction_msgs.append(f"ğŸ“ **æ‰¹æ”¹èˆ‡åˆ†æï¼š**\n{result}")
                
                # 3. å¯«å…¥ Log (åªå­˜å‰ 50 å­—é¿å…éé•·)
                user_data["translation_log"].append(f"{today_str}: {text[:50]}")
                is_user_updated = True
                
                time.sleep(2) # é¿å… API éç†±

        # === çµç®—æ•¸æ“š ===
        if user_data["stats"]["last_active"] != today_str:
            # çµç®—æ˜¨å¤©çš„åŠªåŠ›ç¨‹åº¦
            user_data["stats"]["yesterday_answers_count"] = today_answers_accumulated
            
            # æ›´æ–° Streak (åªè¦æœ‰äº’å‹•å°±ç®—)
            if today_answers_accumulated > 0 or is_vocab_updated or is_user_updated:
                 yesterday = str((datetime.now() - timedelta(days=1)).date())
                 if user_data["stats"]["last_active"] == yesterday:
                     user_data["stats"]["streak_days"] += 1
                 else:
                     user_data["stats"]["streak_days"] = 1
                 user_data["stats"]["last_active"] = today_str
                 is_user_updated = True

        # === ç™¼é€è¨Šæ¯ ===
        if updates_log: send_telegram("\n".join(set(updates_log)))
        for msg in correction_msgs:
            send_telegram(msg)
            time.sleep(1)

        return vocab_data, user_data

    except Exception as e:
        print(f"Error: {e}")
        return load_json(VOCAB_FILE, {}), load_json(USER_DATA_FILE, {})

# ================= æ¯æ—¥ç‰¹è¨“ç”Ÿæˆ =================

def run_daily_quiz(vocab, user):
    if not vocab.get("words"):
        send_telegram("ğŸ“­ å–®å­—åº«ç©ºçš„ï¼å¿«å‚³å–®å­—çµ¦æˆ‘ï¼")
        return

    # 1. åˆ¤æ–·å·æ‡¶ç¨‹åº¦
    questions_given = user["stats"].get("last_quiz_questions_count", 0)
    answers_given = user["stats"].get("yesterday_answers_count", 0)
    
    answer_rate = 0
    if questions_given > 0:
        answer_rate = answers_given / questions_given
    
    # æƒ…ç·’ Prompt
    emotion_prompt = ""
    if questions_given == 0:
        emotion_prompt = "é€™æ˜¯ç¬¬ä¸€æ¬¡å‡ºé¡Œï¼Œè«‹ç”¨å……æ»¿æ´»åŠ›èˆ‡å¸Œæœ›çš„èªæ°£æ­¡è¿ä½¿ç”¨è€…ã€‚"
    elif answer_rate >= 0.8:
        emotion_prompt = f"æ˜¨æ—¥å‡ºé¡Œ {questions_given}ï¼Œå¥¹å›è¦† {answers_given} (åŠä»¥ä¸Š)ã€‚å¤ªæ£’äº†ï¼è«‹å¤§åŠ›èª‡çå¥¹çš„è‡ªå¾‹ï¼Œä¸¦é¼“å‹µä¿æŒã€‚"
    elif answer_rate >= 0.3:
        emotion_prompt = f"æ˜¨æ—¥å‡ºé¡Œ {questions_given}ï¼Œå¥¹å›è¦† {answers_given}ã€‚è«‹ç”¨ã€Œå‹‰å¼·æ¥å—ã€çš„èªæ°£ï¼Œè‚¯å®šå¥¹æœ‰ç·´ç¿’ï¼Œä½†æé†’é¡Œæ•¸é‚„å¯ä»¥æ›´å¤šã€‚"
    else:
        emotion_prompt = f"æ˜¨æ—¥å‡ºé¡Œ {questions_given}ï¼Œå¥¹åªå›è¦† {answers_given} (ç”šè‡³å¯èƒ½ç‚º 0)ã€‚è«‹é–‹å•Ÿã€æƒ…å‹’æ¨¡å¼ ğŸ˜ˆã€‘ï¼Œè³ªå•å¥¹ç‚ºä»€éº¼ç„¡è¦–ä½œæ¥­ï¼Ÿæ˜¯ä¸æ˜¯æƒ³æ”¾æ£„æ—¥æ–‡ï¼Ÿ"

    # 2. å‡ºé¡Œ
    weights = [w.get("count", 1) * 5 for w in vocab["words"]]
    k = min(10, len(vocab["words"]))
    selected_words = random.choices(vocab["words"], weights=weights, k=k)
    word_list = "\n".join([f"{w['kanji']} ({w['meaning']})" for w in selected_words])
    
    today_questions_count = 10
    user["stats"]["last_quiz_questions_count"] = today_questions_count
    user["stats"]["last_quiz_date"] = str(datetime.now().date())

    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel(MODEL_NAME)

    print("ğŸ¤– AI ç”Ÿæˆæ¸¬é©—ä¸­...")
    prompt = f"""
    ä½ æ˜¯æ—¥æ–‡ N2 æ–¯å·´é”æ•™ç·´ã€‚
    
    ã€æƒ…ç·’è¨­å®šã€‘
    {emotion_prompt}
    
    ã€é¡Œç›®ç”Ÿæˆã€‘
    å–®å­—åº«ï¼š
    {word_list}
    
    è«‹è£½ä½œ **10 é¡Œ** ç¿»è­¯æ¸¬é©—ï¼š
    - **7 é¡Œï¼šä¸­ç¿»æ—¥** (å¼·è¿«è¼¸å‡º)
    - **3 é¡Œï¼šæ—¥ç¿»ä¸­**
    
    ã€æ ¼å¼ã€‘
    ç¹é«”ä¸­æ–‡ + Emojiã€‚é¡Œç›®èˆ‡è§£ç­”åˆ†é–‹ã€‚
    """
    
    try:
        response = model.generate_content(prompt, safety_settings=SAFETY_SETTINGS)
        if response.text:
            send_telegram(response.text)
    except:
        send_telegram("âš ï¸ æ¸¬é©—ç”Ÿæˆå¤±æ•—")
    
    return user

if __name__ == "__main__":
    # 1. è™•ç†è³‡æ–™
    v_data, u_data = process_data()
    
    # 2. åŸ·è¡Œæ¸¬é©—
    u_data_updated = run_daily_quiz(v_data, u_data)
    
    # 3. å­˜æª”
    save_json(VOCAB_FILE, v_data)
    if u_data_updated:
        save_json(USER_DATA_FILE, u_data_updated)
    else:
        save_json(USER_DATA_FILE, u_data)